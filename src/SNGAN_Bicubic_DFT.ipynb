{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1280 images belonging to 2 classes.\n",
      "Found 320 images belonging to 2 classes.\n",
      "Found 400 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'SNGAN_bicubic_test': 0, 'imagewoof_test': 1}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train = ImageDataGenerator(rescale=1/255,validation_split=0.2)\n",
    "test = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_dataset = train.flow_from_directory(\"/Users/nayansavaliya/Masters Mechatronics/2022 Summer/RAML - Project/data/bicubic/train\",\n",
    "                                          target_size=(32,32),\n",
    "                                          color_mode=\"grayscale\",\n",
    "                                          batch_size =50,\n",
    "                                          class_mode = 'binary',\n",
    "                                          subset='training',)\n",
    "\n",
    "validation_dataset = train.flow_from_directory(\"/Users/nayansavaliya/Masters Mechatronics/2022 Summer/RAML - Project/data/bicubic/train\",\n",
    "                                          target_size=(32,32),\n",
    "                                          color_mode=\"grayscale\",\n",
    "                                          batch_size = 50,\n",
    "                                          class_mode = 'binary',\n",
    "                                          subset='validation')                                    \n",
    "test_dataset = test.flow_from_directory(\"/Users/nayansavaliya/Masters Mechatronics/2022 Summer/RAML - Project/data/bicubic/test\",\n",
    "                                          target_size=(32,32),\n",
    "                                          color_mode=\"grayscale\",\n",
    "                                          batch_size =50,\n",
    "                                          class_mode = 'binary')\n",
    "\n",
    "test_dataset.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PowerSpectrum(object):\n",
    "    \"\"\" Class for calculating a the power spectrum (1D or 2D) of an image in tensorflow.\n",
    "        Expects square image as input.\n",
    "    \"\"\"\n",
    "    def __init__(self,image_size=None,scale=1):\n",
    "        \"\"\"image_size: only needed for power1D\n",
    "        \"\"\"\n",
    "        self.image_size = image_size\n",
    "        self.scale = scale\n",
    "        if self.image_size is not None:\n",
    "            self.az_mask=self.build_azimuthal_mask()\n",
    "        \n",
    "    def power2D(self,x):\n",
    "        x = tf.signal.fft2d(tf.cast(x,dtype=tf.complex64))\n",
    "        x = tf.signal.fftshift(x, axes=None, name=None)\n",
    "        return abs(x)\n",
    "     \n",
    "    def build_azimuthal_mask(self):\n",
    "        \n",
    "        x,y = np.meshgrid(np.arange(self.image_size),np.arange(self.image_size))\n",
    "        R = np.sqrt((x-self.image_size/2)**2+(y-self.image_size/2)**2)\n",
    "        masks = np.array(list(map(lambda r : (R >= r-.5) & (R < r+.5),np.arange(1,int(self.image_size/2+1),1))))\n",
    "        norm = np.sum(masks,axis=(1,2),keepdims=True)\n",
    "        masks=masks/norm\n",
    "        n=len(masks)\n",
    "        return tf.reshape(tf.cast(masks,dtype=tf.float32),(1,n,self.image_size,self.image_size))\n",
    "        \n",
    "    def az_average(self,x):\n",
    "        x=tf.reshape(x,(-1,1,self.image_size,self.image_size))\n",
    "        return tf.reduce_sum(tf.reduce_sum(tf.multiply(self.az_mask,x),axis=3),axis=2)\n",
    "    \n",
    "    def power1D(self,x):\n",
    "        x = self.power2D(x)\n",
    "        az_avg = self.az_average(x)\n",
    "        ell=np.arange(int(az_avg.shape[1]))*9\n",
    "        return tf.multiply(az_avg,tf.reshape(tf.cast(ell*(ell+1)/2/np.pi,dtype=tf.float32),(1,-1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-19 14:39:05.496011: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-05-19 14:39:05.496233: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "ps = PowerSpectrum(32)\n",
    "model.add(keras.layers.Lambda(lambda v: ps.power1D(v)))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32,input_dim=32,activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training\n",
    "\n",
    "Usually with every epoch increasing, loss goes lower and accuracy goes higher. But with val_loss and val_acc, many cases can be possible:\n",
    "\n",
    "val_loss starts increasing, val_acc starts decreasing(means model is cramming values not learning)\n",
    "\n",
    "val_loss starts increasing, val_acc also increases.(could be case of overfitting or diverse probability values in cases softmax is used in output layer)\n",
    "\n",
    "val_loss starts decreasing, val_acc starts increasing(Correct, means model build is learning and working fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-19 14:39:05.820483: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-05-19 14:39:06.169229: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 21ms/step - loss: 205.0917 - accuracy: 0.4805 - val_loss: 30.9653 - val_accuracy: 0.4750\n",
      "Epoch 2/500\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 28.3673 - accuracy: 0.4200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-19 14:39:06.838180: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 12ms/step - loss: 34.3726 - accuracy: 0.4922 - val_loss: 23.4837 - val_accuracy: 0.5031\n",
      "Epoch 3/500\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 26.6018 - accuracy: 0.4938 - val_loss: 21.2562 - val_accuracy: 0.5312\n",
      "Epoch 4/500\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 23.0498 - accuracy: 0.5148 - val_loss: 25.5606 - val_accuracy: 0.4906\n",
      "Epoch 5/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 24.1443 - accuracy: 0.4938 - val_loss: 22.2939 - val_accuracy: 0.4719\n",
      "Epoch 6/500\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 20.5899 - accuracy: 0.5094 - val_loss: 18.8019 - val_accuracy: 0.4656\n",
      "Epoch 7/500\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 21.9430 - accuracy: 0.4867 - val_loss: 17.3092 - val_accuracy: 0.5250\n",
      "Epoch 8/500\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 20.0340 - accuracy: 0.4805 - val_loss: 17.8784 - val_accuracy: 0.4813\n",
      "Epoch 9/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 16.8021 - accuracy: 0.5281 - val_loss: 19.8195 - val_accuracy: 0.5219\n",
      "Epoch 10/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 19.1083 - accuracy: 0.5016 - val_loss: 16.7690 - val_accuracy: 0.4938\n",
      "Epoch 11/500\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 17.1563 - accuracy: 0.5000 - val_loss: 16.1335 - val_accuracy: 0.4750\n",
      "Epoch 12/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 16.7298 - accuracy: 0.5039 - val_loss: 14.3444 - val_accuracy: 0.5188\n",
      "Epoch 13/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 16.5178 - accuracy: 0.5039 - val_loss: 13.7470 - val_accuracy: 0.5344\n",
      "Epoch 14/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 15.6983 - accuracy: 0.5273 - val_loss: 12.9827 - val_accuracy: 0.4969\n",
      "Epoch 15/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 15.0564 - accuracy: 0.5117 - val_loss: 15.7226 - val_accuracy: 0.4813\n",
      "Epoch 16/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 17.0343 - accuracy: 0.4875 - val_loss: 18.4315 - val_accuracy: 0.5063\n",
      "Epoch 17/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 14.4056 - accuracy: 0.5016 - val_loss: 14.0614 - val_accuracy: 0.4719\n",
      "Epoch 18/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 14.2431 - accuracy: 0.4875 - val_loss: 11.6326 - val_accuracy: 0.5344\n",
      "Epoch 19/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 13.7600 - accuracy: 0.4984 - val_loss: 11.8247 - val_accuracy: 0.4781\n",
      "Epoch 20/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 13.9735 - accuracy: 0.5109 - val_loss: 11.7420 - val_accuracy: 0.5094\n",
      "Epoch 21/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 12.7350 - accuracy: 0.4922 - val_loss: 11.3471 - val_accuracy: 0.4938\n",
      "Epoch 22/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 12.3493 - accuracy: 0.4859 - val_loss: 15.0950 - val_accuracy: 0.4906\n",
      "Epoch 23/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 12.5504 - accuracy: 0.5078 - val_loss: 8.6409 - val_accuracy: 0.5125\n",
      "Epoch 24/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 11.2704 - accuracy: 0.4859 - val_loss: 9.1638 - val_accuracy: 0.4969\n",
      "Epoch 25/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 10.3736 - accuracy: 0.5188 - val_loss: 11.8058 - val_accuracy: 0.4875\n",
      "Epoch 26/500\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 11.5065 - accuracy: 0.4758 - val_loss: 10.9756 - val_accuracy: 0.4813\n",
      "Epoch 27/500\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 10.6329 - accuracy: 0.5039 - val_loss: 9.5647 - val_accuracy: 0.5156\n",
      "Epoch 28/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 10.6500 - accuracy: 0.4883 - val_loss: 9.1517 - val_accuracy: 0.4938\n",
      "Epoch 29/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 9.3510 - accuracy: 0.5008 - val_loss: 9.1202 - val_accuracy: 0.5500\n",
      "Epoch 30/500\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 9.5118 - accuracy: 0.4828 - val_loss: 8.7511 - val_accuracy: 0.4938\n",
      "Epoch 31/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 10.0543 - accuracy: 0.4805 - val_loss: 8.1552 - val_accuracy: 0.4625\n",
      "Epoch 32/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 11.8273 - accuracy: 0.4914 - val_loss: 8.3171 - val_accuracy: 0.5125\n",
      "Epoch 33/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 9.5657 - accuracy: 0.5039 - val_loss: 6.9654 - val_accuracy: 0.4906\n",
      "Epoch 34/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.3742 - accuracy: 0.5039 - val_loss: 9.4462 - val_accuracy: 0.4781\n",
      "Epoch 35/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.4319 - accuracy: 0.5180 - val_loss: 6.4445 - val_accuracy: 0.4938\n",
      "Epoch 36/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 8.7891 - accuracy: 0.4891 - val_loss: 7.0155 - val_accuracy: 0.5188\n",
      "Epoch 37/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 7.9030 - accuracy: 0.4906 - val_loss: 6.7738 - val_accuracy: 0.4969\n",
      "Epoch 38/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.2527 - accuracy: 0.5281 - val_loss: 7.5328 - val_accuracy: 0.4781\n",
      "Epoch 39/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.9127 - accuracy: 0.5094 - val_loss: 8.0110 - val_accuracy: 0.4563\n",
      "Epoch 40/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 7.8335 - accuracy: 0.4852 - val_loss: 7.0897 - val_accuracy: 0.5125\n",
      "Epoch 41/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.7192 - accuracy: 0.5031 - val_loss: 7.1181 - val_accuracy: 0.5031\n",
      "Epoch 42/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 10.7271 - accuracy: 0.4711 - val_loss: 12.5191 - val_accuracy: 0.4813\n",
      "Epoch 43/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.0583 - accuracy: 0.4953 - val_loss: 5.8750 - val_accuracy: 0.5250\n",
      "Epoch 44/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.7269 - accuracy: 0.5203 - val_loss: 5.7815 - val_accuracy: 0.5437\n",
      "Epoch 45/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.7536 - accuracy: 0.5266 - val_loss: 6.4512 - val_accuracy: 0.4875\n",
      "Epoch 46/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.8184 - accuracy: 0.5031 - val_loss: 7.0541 - val_accuracy: 0.5063\n",
      "Epoch 47/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.6447 - accuracy: 0.4891 - val_loss: 6.4910 - val_accuracy: 0.5000\n",
      "Epoch 48/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.5157 - accuracy: 0.4984 - val_loss: 6.4520 - val_accuracy: 0.4781\n",
      "Epoch 49/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.0018 - accuracy: 0.5312 - val_loss: 6.5513 - val_accuracy: 0.4750\n",
      "Epoch 50/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 6.4627 - accuracy: 0.5164 - val_loss: 5.9682 - val_accuracy: 0.5281\n",
      "Epoch 51/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.0029 - accuracy: 0.5039 - val_loss: 6.9837 - val_accuracy: 0.5219\n",
      "Epoch 52/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 6.2772 - accuracy: 0.5164 - val_loss: 5.8962 - val_accuracy: 0.5188\n",
      "Epoch 53/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.1138 - accuracy: 0.5008 - val_loss: 5.1134 - val_accuracy: 0.5344\n",
      "Epoch 54/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.2191 - accuracy: 0.4906 - val_loss: 4.9977 - val_accuracy: 0.5281\n",
      "Epoch 55/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.3442 - accuracy: 0.5141 - val_loss: 5.8954 - val_accuracy: 0.5000\n",
      "Epoch 56/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.3523 - accuracy: 0.5031 - val_loss: 5.7208 - val_accuracy: 0.5063\n",
      "Epoch 57/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.9191 - accuracy: 0.4938 - val_loss: 5.3453 - val_accuracy: 0.4813\n",
      "Epoch 58/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.7884 - accuracy: 0.5242 - val_loss: 7.5951 - val_accuracy: 0.4875\n",
      "Epoch 59/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.4124 - accuracy: 0.5016 - val_loss: 5.9014 - val_accuracy: 0.5094\n",
      "Epoch 60/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.2171 - accuracy: 0.5250 - val_loss: 4.9478 - val_accuracy: 0.4938\n",
      "Epoch 61/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.4337 - accuracy: 0.4953 - val_loss: 5.1142 - val_accuracy: 0.5000\n",
      "Epoch 62/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.2325 - accuracy: 0.5148 - val_loss: 5.6307 - val_accuracy: 0.4844\n",
      "Epoch 63/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.4772 - accuracy: 0.5016 - val_loss: 5.1972 - val_accuracy: 0.5188\n",
      "Epoch 64/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.7870 - accuracy: 0.4781 - val_loss: 10.9454 - val_accuracy: 0.4906\n",
      "Epoch 65/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 8.2955 - accuracy: 0.4805 - val_loss: 4.2063 - val_accuracy: 0.5500\n",
      "Epoch 66/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.1926 - accuracy: 0.4961 - val_loss: 4.4537 - val_accuracy: 0.5063\n",
      "Epoch 67/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.1608 - accuracy: 0.4891 - val_loss: 6.7639 - val_accuracy: 0.4938\n",
      "Epoch 68/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 7.4013 - accuracy: 0.5000 - val_loss: 4.5692 - val_accuracy: 0.5219\n",
      "Epoch 69/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.6954 - accuracy: 0.5117 - val_loss: 4.5811 - val_accuracy: 0.4594\n",
      "Epoch 70/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.9992 - accuracy: 0.4703 - val_loss: 5.2042 - val_accuracy: 0.5156\n",
      "Epoch 71/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.4027 - accuracy: 0.5203 - val_loss: 4.0635 - val_accuracy: 0.5219\n",
      "Epoch 72/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.1814 - accuracy: 0.4852 - val_loss: 4.8186 - val_accuracy: 0.4563\n",
      "Epoch 73/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.3174 - accuracy: 0.5102 - val_loss: 4.6272 - val_accuracy: 0.5281\n",
      "Epoch 74/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.6880 - accuracy: 0.5063 - val_loss: 5.2651 - val_accuracy: 0.4969\n",
      "Epoch 75/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.1524 - accuracy: 0.4906 - val_loss: 4.3355 - val_accuracy: 0.4531\n",
      "Epoch 76/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.3693 - accuracy: 0.4875 - val_loss: 5.8505 - val_accuracy: 0.5063\n",
      "Epoch 77/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.0407 - accuracy: 0.4961 - val_loss: 3.9534 - val_accuracy: 0.5219\n",
      "Epoch 78/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.3731 - accuracy: 0.5133 - val_loss: 4.6362 - val_accuracy: 0.4938\n",
      "Epoch 79/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.2432 - accuracy: 0.4688 - val_loss: 3.9945 - val_accuracy: 0.5156\n",
      "Epoch 80/500\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.8350 - accuracy: 0.4922 - val_loss: 4.8422 - val_accuracy: 0.5094\n",
      "Epoch 81/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.2263 - accuracy: 0.4875 - val_loss: 5.5153 - val_accuracy: 0.4969\n",
      "Epoch 82/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8884 - accuracy: 0.5125 - val_loss: 3.8664 - val_accuracy: 0.4437\n",
      "Epoch 83/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.6827 - accuracy: 0.5164 - val_loss: 3.7652 - val_accuracy: 0.4781\n",
      "Epoch 84/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.0461 - accuracy: 0.5180 - val_loss: 4.0474 - val_accuracy: 0.4469\n",
      "Epoch 85/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.1231 - accuracy: 0.4852 - val_loss: 4.0864 - val_accuracy: 0.4781\n",
      "Epoch 86/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.6342 - accuracy: 0.4938 - val_loss: 3.0026 - val_accuracy: 0.5250\n",
      "Epoch 87/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.5200 - accuracy: 0.5023 - val_loss: 4.9310 - val_accuracy: 0.4750\n",
      "Epoch 88/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.5462 - accuracy: 0.4813 - val_loss: 3.1340 - val_accuracy: 0.5219\n",
      "Epoch 89/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.6586 - accuracy: 0.4703 - val_loss: 3.0984 - val_accuracy: 0.5125\n",
      "Epoch 90/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.1177 - accuracy: 0.4930 - val_loss: 3.1852 - val_accuracy: 0.4688\n",
      "Epoch 91/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.3247 - accuracy: 0.4938 - val_loss: 10.6323 - val_accuracy: 0.5000\n",
      "Epoch 92/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.3902 - accuracy: 0.5039 - val_loss: 3.1435 - val_accuracy: 0.4813\n",
      "Epoch 93/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.6672 - accuracy: 0.4906 - val_loss: 3.0009 - val_accuracy: 0.4938\n",
      "Epoch 94/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 2.9311 - accuracy: 0.5063 - val_loss: 5.3201 - val_accuracy: 0.4781\n",
      "Epoch 95/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.3976 - accuracy: 0.4930 - val_loss: 3.2725 - val_accuracy: 0.4688\n",
      "Epoch 96/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.1177 - accuracy: 0.5063 - val_loss: 4.9229 - val_accuracy: 0.4906\n",
      "Epoch 97/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.9084 - accuracy: 0.4844 - val_loss: 7.1244 - val_accuracy: 0.5000\n",
      "Epoch 98/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.9193 - accuracy: 0.5078 - val_loss: 3.9108 - val_accuracy: 0.4719\n",
      "Epoch 99/500\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.7298 - accuracy: 0.4844 - val_loss: 2.8684 - val_accuracy: 0.5094\n",
      "Epoch 100/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.4585 - accuracy: 0.5141 - val_loss: 3.0466 - val_accuracy: 0.5094\n",
      "Epoch 101/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.5095 - accuracy: 0.4969 - val_loss: 2.7979 - val_accuracy: 0.5125\n",
      "Epoch 102/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8110 - accuracy: 0.4961 - val_loss: 6.4535 - val_accuracy: 0.5063\n",
      "Epoch 103/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.6085 - accuracy: 0.5008 - val_loss: 2.3954 - val_accuracy: 0.4844\n",
      "Epoch 104/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.3992 - accuracy: 0.5086 - val_loss: 2.8578 - val_accuracy: 0.4469\n",
      "Epoch 105/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.5385 - accuracy: 0.4922 - val_loss: 2.8697 - val_accuracy: 0.4938\n",
      "Epoch 106/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.0668 - accuracy: 0.5063 - val_loss: 2.4819 - val_accuracy: 0.5094\n",
      "Epoch 107/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 2.5533 - accuracy: 0.5141 - val_loss: 2.3395 - val_accuracy: 0.4906\n",
      "Epoch 108/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8866 - accuracy: 0.4922 - val_loss: 3.3223 - val_accuracy: 0.4813\n",
      "Epoch 109/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.9855 - accuracy: 0.5148 - val_loss: 2.3807 - val_accuracy: 0.4844\n",
      "Epoch 110/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.4088 - accuracy: 0.4938 - val_loss: 2.9305 - val_accuracy: 0.5406\n",
      "Epoch 111/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 6.2317 - accuracy: 0.5016 - val_loss: 6.1271 - val_accuracy: 0.4938\n",
      "Epoch 112/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.2531 - accuracy: 0.5133 - val_loss: 3.5684 - val_accuracy: 0.4531\n",
      "Epoch 113/500\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.9045 - accuracy: 0.5133 - val_loss: 3.5976 - val_accuracy: 0.5406\n",
      "Epoch 114/500\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 2.9808 - accuracy: 0.4758 - val_loss: 3.7318 - val_accuracy: 0.4781\n",
      "Epoch 115/500\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.4487 - accuracy: 0.5094 - val_loss: 4.6105 - val_accuracy: 0.5000\n",
      "Epoch 116/500\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.7308 - accuracy: 0.4820 - val_loss: 3.6575 - val_accuracy: 0.5063\n",
      "Epoch 117/500\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 2.8343 - accuracy: 0.4891 - val_loss: 2.3124 - val_accuracy: 0.5125\n",
      "Epoch 118/500\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.1079 - accuracy: 0.5258 - val_loss: 2.5378 - val_accuracy: 0.4906\n",
      "Epoch 119/500\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.2559 - accuracy: 0.5023 - val_loss: 3.2065 - val_accuracy: 0.4875\n",
      "Epoch 120/500\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 2.8665 - accuracy: 0.4898 - val_loss: 4.5175 - val_accuracy: 0.4844\n",
      "Epoch 121/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 2.7944 - accuracy: 0.5211 - val_loss: 1.8300 - val_accuracy: 0.5125\n",
      "Epoch 122/500\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 2.7232 - accuracy: 0.5039 - val_loss: 3.1365 - val_accuracy: 0.5000\n",
      "Epoch 123/500\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 2.1900 - accuracy: 0.5078 - val_loss: 2.0347 - val_accuracy: 0.4969\n",
      "Epoch 124/500\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.0015 - accuracy: 0.4789 - val_loss: 3.7598 - val_accuracy: 0.5031\n",
      "Epoch 125/500\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.7961 - accuracy: 0.4977 - val_loss: 3.8272 - val_accuracy: 0.4969\n",
      "Epoch 126/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.0933 - accuracy: 0.4797 - val_loss: 1.9691 - val_accuracy: 0.5188\n",
      "Epoch 127/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.2638 - accuracy: 0.4906 - val_loss: 3.3117 - val_accuracy: 0.4969\n",
      "Epoch 128/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.2488 - accuracy: 0.4914 - val_loss: 1.9498 - val_accuracy: 0.4656\n",
      "Epoch 129/500\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 2.2764 - accuracy: 0.5219 - val_loss: 1.6663 - val_accuracy: 0.5125\n",
      "Epoch 130/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 2.6917 - accuracy: 0.5117 - val_loss: 1.7658 - val_accuracy: 0.5125\n",
      "Epoch 131/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.7394 - accuracy: 0.4633 - val_loss: 3.4746 - val_accuracy: 0.4906\n",
      "Epoch 132/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.8591 - accuracy: 0.5117 - val_loss: 3.3020 - val_accuracy: 0.5125\n",
      "Epoch 133/500\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 2.6643 - accuracy: 0.5016 - val_loss: 3.9919 - val_accuracy: 0.5094\n",
      "Epoch 134/500\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 2.1892 - accuracy: 0.4766 - val_loss: 4.0864 - val_accuracy: 0.4875\n",
      "Epoch 135/500\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 2.9156 - accuracy: 0.4992 - val_loss: 1.6292 - val_accuracy: 0.5125\n",
      "Epoch 136/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.2594 - accuracy: 0.5422 - val_loss: 1.5632 - val_accuracy: 0.5125\n",
      "Epoch 137/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.8517 - accuracy: 0.4938 - val_loss: 1.5047 - val_accuracy: 0.5500\n",
      "Epoch 138/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 2.4888 - accuracy: 0.4961 - val_loss: 5.2776 - val_accuracy: 0.4969\n",
      "Epoch 139/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.8109 - accuracy: 0.5141 - val_loss: 4.8077 - val_accuracy: 0.5063\n",
      "Epoch 140/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.1830 - accuracy: 0.4789 - val_loss: 3.1997 - val_accuracy: 0.4938\n",
      "Epoch 141/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.1995 - accuracy: 0.4859 - val_loss: 2.5234 - val_accuracy: 0.4844\n",
      "Epoch 142/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.5463 - accuracy: 0.4836 - val_loss: 8.1784 - val_accuracy: 0.5000\n",
      "Epoch 143/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.2639 - accuracy: 0.5086 - val_loss: 2.9759 - val_accuracy: 0.4906\n",
      "Epoch 144/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.3841 - accuracy: 0.5109 - val_loss: 8.5707 - val_accuracy: 0.5000\n",
      "Epoch 145/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 6.3495 - accuracy: 0.5023 - val_loss: 5.8743 - val_accuracy: 0.4938\n",
      "Epoch 146/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.3293 - accuracy: 0.4773 - val_loss: 5.7485 - val_accuracy: 0.5000\n",
      "Epoch 147/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.1088 - accuracy: 0.4672 - val_loss: 2.7497 - val_accuracy: 0.5156\n",
      "Epoch 148/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.7907 - accuracy: 0.4758 - val_loss: 1.5824 - val_accuracy: 0.5188\n",
      "Epoch 149/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.8698 - accuracy: 0.4875 - val_loss: 1.2674 - val_accuracy: 0.5469\n",
      "Epoch 150/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.0807 - accuracy: 0.5117 - val_loss: 5.4817 - val_accuracy: 0.5000\n",
      "Epoch 151/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.0827 - accuracy: 0.4859 - val_loss: 1.8006 - val_accuracy: 0.5094\n",
      "Epoch 152/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.8468 - accuracy: 0.4992 - val_loss: 3.1064 - val_accuracy: 0.5000\n",
      "Epoch 153/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.7085 - accuracy: 0.5234 - val_loss: 1.1902 - val_accuracy: 0.5375\n",
      "Epoch 154/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.5145 - accuracy: 0.4945 - val_loss: 1.3074 - val_accuracy: 0.5031\n",
      "Epoch 155/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.1898 - accuracy: 0.4898 - val_loss: 1.4861 - val_accuracy: 0.5281\n",
      "Epoch 156/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.3509 - accuracy: 0.5109 - val_loss: 7.5640 - val_accuracy: 0.5000\n",
      "Epoch 157/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.6934 - accuracy: 0.4953 - val_loss: 1.6771 - val_accuracy: 0.4750\n",
      "Epoch 158/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.0508 - accuracy: 0.4961 - val_loss: 2.6208 - val_accuracy: 0.5063\n",
      "Epoch 159/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.8157 - accuracy: 0.4875 - val_loss: 2.7533 - val_accuracy: 0.4969\n",
      "Epoch 160/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.5662 - accuracy: 0.4797 - val_loss: 4.5301 - val_accuracy: 0.5063\n",
      "Epoch 161/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.6757 - accuracy: 0.5203 - val_loss: 1.8917 - val_accuracy: 0.5188\n",
      "Epoch 162/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.1985 - accuracy: 0.4859 - val_loss: 2.3156 - val_accuracy: 0.5000\n",
      "Epoch 163/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.6774 - accuracy: 0.4945 - val_loss: 2.9854 - val_accuracy: 0.4969\n",
      "Epoch 164/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 7.1054 - accuracy: 0.5117 - val_loss: 5.8244 - val_accuracy: 0.5063\n",
      "Epoch 165/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.6049 - accuracy: 0.4875 - val_loss: 1.4976 - val_accuracy: 0.4813\n",
      "Epoch 166/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 2.3626 - accuracy: 0.4945 - val_loss: 1.3857 - val_accuracy: 0.5188\n",
      "Epoch 167/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.7789 - accuracy: 0.5055 - val_loss: 5.6706 - val_accuracy: 0.5000\n",
      "Epoch 168/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.2269 - accuracy: 0.4938 - val_loss: 6.0933 - val_accuracy: 0.5031\n",
      "Epoch 169/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.1745 - accuracy: 0.4977 - val_loss: 1.0508 - val_accuracy: 0.5406\n",
      "Epoch 170/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.5722 - accuracy: 0.5039 - val_loss: 1.8212 - val_accuracy: 0.4813\n",
      "Epoch 171/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 2.8335 - accuracy: 0.4977 - val_loss: 2.5824 - val_accuracy: 0.5031\n",
      "Epoch 172/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.8630 - accuracy: 0.5016 - val_loss: 1.6743 - val_accuracy: 0.5063\n",
      "Epoch 173/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.1914 - accuracy: 0.5094 - val_loss: 4.5234 - val_accuracy: 0.5000\n",
      "Epoch 174/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.8916 - accuracy: 0.4828 - val_loss: 7.9221 - val_accuracy: 0.4969\n",
      "Epoch 175/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.1973 - accuracy: 0.5102 - val_loss: 1.2739 - val_accuracy: 0.5125\n",
      "Epoch 176/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.7841 - accuracy: 0.4648 - val_loss: 3.5134 - val_accuracy: 0.5063\n",
      "Epoch 177/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.1536 - accuracy: 0.4828 - val_loss: 1.2425 - val_accuracy: 0.4969\n",
      "Epoch 178/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.7734 - accuracy: 0.5164 - val_loss: 1.7924 - val_accuracy: 0.4938\n",
      "Epoch 179/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.4466 - accuracy: 0.5203 - val_loss: 1.4907 - val_accuracy: 0.4719\n",
      "Epoch 180/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.7307 - accuracy: 0.5156 - val_loss: 10.3948 - val_accuracy: 0.5000\n",
      "Epoch 181/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 6.2996 - accuracy: 0.4703 - val_loss: 13.0035 - val_accuracy: 0.5000\n",
      "Epoch 182/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 6.4370 - accuracy: 0.4852 - val_loss: 1.8581 - val_accuracy: 0.5188\n",
      "Epoch 183/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.8962 - accuracy: 0.4922 - val_loss: 1.2462 - val_accuracy: 0.4500\n",
      "Epoch 184/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 6.6047 - accuracy: 0.4953 - val_loss: 9.1763 - val_accuracy: 0.5000\n",
      "Epoch 185/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.5594 - accuracy: 0.4953 - val_loss: 1.4206 - val_accuracy: 0.4688\n",
      "Epoch 186/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.0220 - accuracy: 0.5312 - val_loss: 1.0150 - val_accuracy: 0.5375\n",
      "Epoch 187/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.8315 - accuracy: 0.4813 - val_loss: 1.6033 - val_accuracy: 0.5000\n",
      "Epoch 188/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.3018 - accuracy: 0.5094 - val_loss: 1.3372 - val_accuracy: 0.5188\n",
      "Epoch 189/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.2997 - accuracy: 0.4875 - val_loss: 4.8510 - val_accuracy: 0.5000\n",
      "Epoch 190/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.0274 - accuracy: 0.5063 - val_loss: 3.5461 - val_accuracy: 0.5000\n",
      "Epoch 191/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.9479 - accuracy: 0.5180 - val_loss: 1.4184 - val_accuracy: 0.5000\n",
      "Epoch 192/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.2375 - accuracy: 0.4961 - val_loss: 1.7532 - val_accuracy: 0.4938\n",
      "Epoch 193/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.2219 - accuracy: 0.5195 - val_loss: 5.1027 - val_accuracy: 0.5000\n",
      "Epoch 194/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.1123 - accuracy: 0.5031 - val_loss: 1.2124 - val_accuracy: 0.5031\n",
      "Epoch 195/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.7897 - accuracy: 0.5117 - val_loss: 2.1990 - val_accuracy: 0.4906\n",
      "Epoch 196/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.3902 - accuracy: 0.5008 - val_loss: 6.2760 - val_accuracy: 0.5000\n",
      "Epoch 197/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.4992 - accuracy: 0.4930 - val_loss: 1.0390 - val_accuracy: 0.5094\n",
      "Epoch 198/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.2373 - accuracy: 0.4953 - val_loss: 0.9848 - val_accuracy: 0.5125\n",
      "Epoch 199/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.9322 - accuracy: 0.4891 - val_loss: 11.8523 - val_accuracy: 0.5000\n",
      "Epoch 200/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.8601 - accuracy: 0.4813 - val_loss: 1.9509 - val_accuracy: 0.4969\n",
      "Epoch 201/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.4494 - accuracy: 0.5109 - val_loss: 9.1968 - val_accuracy: 0.5000\n",
      "Epoch 202/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.1381 - accuracy: 0.5180 - val_loss: 4.8792 - val_accuracy: 0.5000\n",
      "Epoch 203/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.6061 - accuracy: 0.4945 - val_loss: 1.4048 - val_accuracy: 0.5125\n",
      "Epoch 204/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.9511 - accuracy: 0.4836 - val_loss: 3.1087 - val_accuracy: 0.5000\n",
      "Epoch 205/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.6910 - accuracy: 0.5258 - val_loss: 2.2557 - val_accuracy: 0.5000\n",
      "Epoch 206/500\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.7844 - accuracy: 0.5023 - val_loss: 3.4981 - val_accuracy: 0.5000\n",
      "Epoch 207/500\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 2.9767 - accuracy: 0.5070 - val_loss: 2.7709 - val_accuracy: 0.5000\n",
      "Epoch 208/500\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.7765 - accuracy: 0.5031 - val_loss: 2.6393 - val_accuracy: 0.5000\n",
      "Epoch 209/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.8810 - accuracy: 0.4672 - val_loss: 1.1190 - val_accuracy: 0.5000\n",
      "Epoch 210/500\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 1.7554 - accuracy: 0.5031 - val_loss: 1.3719 - val_accuracy: 0.5063\n",
      "Epoch 211/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.2852 - accuracy: 0.5070 - val_loss: 6.0066 - val_accuracy: 0.5000\n",
      "Epoch 212/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 2.9206 - accuracy: 0.4883 - val_loss: 6.8769 - val_accuracy: 0.5000\n",
      "Epoch 213/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.6252 - accuracy: 0.4961 - val_loss: 2.6025 - val_accuracy: 0.5031\n",
      "Epoch 214/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.5112 - accuracy: 0.5094 - val_loss: 2.8694 - val_accuracy: 0.5000\n",
      "Epoch 215/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.8228 - accuracy: 0.5195 - val_loss: 1.6734 - val_accuracy: 0.4969\n",
      "Epoch 216/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.2896 - accuracy: 0.4922 - val_loss: 4.5029 - val_accuracy: 0.5000\n",
      "Epoch 217/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.5090 - accuracy: 0.5117 - val_loss: 0.9279 - val_accuracy: 0.4844\n",
      "Epoch 218/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3511 - accuracy: 0.5133 - val_loss: 1.9359 - val_accuracy: 0.4969\n",
      "Epoch 219/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 2.5506 - accuracy: 0.5156 - val_loss: 2.6708 - val_accuracy: 0.5000\n",
      "Epoch 220/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.5990 - accuracy: 0.5031 - val_loss: 5.0047 - val_accuracy: 0.5000\n",
      "Epoch 221/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.8511 - accuracy: 0.4992 - val_loss: 0.8521 - val_accuracy: 0.4625\n",
      "Epoch 222/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.6727 - accuracy: 0.4938 - val_loss: 2.1923 - val_accuracy: 0.5000\n",
      "Epoch 223/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.9678 - accuracy: 0.4992 - val_loss: 2.0822 - val_accuracy: 0.5000\n",
      "Epoch 224/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.7435 - accuracy: 0.4922 - val_loss: 5.9129 - val_accuracy: 0.5000\n",
      "Epoch 225/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.6058 - accuracy: 0.5070 - val_loss: 2.8319 - val_accuracy: 0.5000\n",
      "Epoch 226/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.2357 - accuracy: 0.4844 - val_loss: 0.8570 - val_accuracy: 0.4625\n",
      "Epoch 227/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.0555 - accuracy: 0.5172 - val_loss: 1.0531 - val_accuracy: 0.5000\n",
      "Epoch 228/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.7325 - accuracy: 0.5141 - val_loss: 4.5932 - val_accuracy: 0.5031\n",
      "Epoch 229/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.9280 - accuracy: 0.5023 - val_loss: 0.8284 - val_accuracy: 0.4781\n",
      "Epoch 230/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.3397 - accuracy: 0.4938 - val_loss: 1.0661 - val_accuracy: 0.5000\n",
      "Epoch 231/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.9176 - accuracy: 0.4914 - val_loss: 4.0069 - val_accuracy: 0.5063\n",
      "Epoch 232/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.1216 - accuracy: 0.5047 - val_loss: 6.3159 - val_accuracy: 0.5031\n",
      "Epoch 233/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.0662 - accuracy: 0.5133 - val_loss: 3.2012 - val_accuracy: 0.5000\n",
      "Epoch 234/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.4929 - accuracy: 0.4883 - val_loss: 0.8056 - val_accuracy: 0.4625\n",
      "Epoch 235/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 2.2195 - accuracy: 0.5047 - val_loss: 3.3137 - val_accuracy: 0.4938\n",
      "Epoch 236/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.8263 - accuracy: 0.4898 - val_loss: 2.4580 - val_accuracy: 0.4938\n",
      "Epoch 237/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.9608 - accuracy: 0.5047 - val_loss: 2.5035 - val_accuracy: 0.5063\n",
      "Epoch 238/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.7415 - accuracy: 0.5188 - val_loss: 1.0282 - val_accuracy: 0.4938\n",
      "Epoch 239/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.8559 - accuracy: 0.5078 - val_loss: 1.4862 - val_accuracy: 0.5031\n",
      "Epoch 240/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.6973 - accuracy: 0.5289 - val_loss: 7.6587 - val_accuracy: 0.5000\n",
      "Epoch 241/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.0532 - accuracy: 0.4852 - val_loss: 3.8819 - val_accuracy: 0.5063\n",
      "Epoch 242/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.7643 - accuracy: 0.4945 - val_loss: 4.1260 - val_accuracy: 0.5031\n",
      "Epoch 243/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.6702 - accuracy: 0.5258 - val_loss: 2.3822 - val_accuracy: 0.5000\n",
      "Epoch 244/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.8652 - accuracy: 0.5117 - val_loss: 3.0521 - val_accuracy: 0.5000\n",
      "Epoch 245/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.5446 - accuracy: 0.4984 - val_loss: 2.4715 - val_accuracy: 0.5000\n",
      "Epoch 246/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.0865 - accuracy: 0.4695 - val_loss: 1.2313 - val_accuracy: 0.5063\n",
      "Epoch 247/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.9968 - accuracy: 0.5008 - val_loss: 5.2490 - val_accuracy: 0.5000\n",
      "Epoch 248/500\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 2.5290 - accuracy: 0.5203 - val_loss: 0.8376 - val_accuracy: 0.5063\n",
      "Epoch 249/500\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.8176 - accuracy: 0.4820 - val_loss: 0.7656 - val_accuracy: 0.5344\n",
      "Epoch 250/500\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.1404 - accuracy: 0.5047 - val_loss: 0.8519 - val_accuracy: 0.5000\n",
      "Epoch 251/500\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 2.3725 - accuracy: 0.5047 - val_loss: 0.8648 - val_accuracy: 0.5094\n",
      "Epoch 252/500\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 2.0570 - accuracy: 0.5203 - val_loss: 5.4584 - val_accuracy: 0.4969\n",
      "Epoch 253/500\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 2.8028 - accuracy: 0.4961 - val_loss: 2.1501 - val_accuracy: 0.5063\n",
      "Epoch 254/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.4824 - accuracy: 0.5000 - val_loss: 0.7664 - val_accuracy: 0.5250\n",
      "Epoch 255/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.5381 - accuracy: 0.5086 - val_loss: 0.9859 - val_accuracy: 0.5063\n",
      "Epoch 256/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.8038 - accuracy: 0.5164 - val_loss: 5.5594 - val_accuracy: 0.4969\n",
      "Epoch 257/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.4359 - accuracy: 0.5406 - val_loss: 4.5199 - val_accuracy: 0.5031\n",
      "Epoch 258/500\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.8373 - accuracy: 0.5070 - val_loss: 2.1593 - val_accuracy: 0.5000\n",
      "Epoch 259/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.1678 - accuracy: 0.4977 - val_loss: 1.7139 - val_accuracy: 0.5000\n",
      "Epoch 260/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.0129 - accuracy: 0.5008 - val_loss: 7.0047 - val_accuracy: 0.5000\n",
      "Epoch 261/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.3258 - accuracy: 0.5031 - val_loss: 3.2892 - val_accuracy: 0.4969\n",
      "Epoch 262/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.1243 - accuracy: 0.5156 - val_loss: 1.5014 - val_accuracy: 0.4969\n",
      "Epoch 263/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.8615 - accuracy: 0.4844 - val_loss: 1.6996 - val_accuracy: 0.5000\n",
      "Epoch 264/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.7973 - accuracy: 0.5109 - val_loss: 1.4179 - val_accuracy: 0.5000\n",
      "Epoch 265/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.1553 - accuracy: 0.4938 - val_loss: 3.3826 - val_accuracy: 0.5000\n",
      "Epoch 266/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.3095 - accuracy: 0.4617 - val_loss: 1.0437 - val_accuracy: 0.4969\n",
      "Epoch 267/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.9112 - accuracy: 0.4961 - val_loss: 5.0271 - val_accuracy: 0.5000\n",
      "Epoch 268/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 2.0817 - accuracy: 0.5125 - val_loss: 0.7927 - val_accuracy: 0.5188\n",
      "Epoch 269/500\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.1333 - accuracy: 0.4984 - val_loss: 3.0850 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    min_delta=0.001, # minimium amount of change to count as an improvement\n",
    "    patience=20, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "        #  steps_per_epoch = 25,\n",
    "         epochs = 500, \n",
    "         callbacks=[early_stopping],\n",
    "         validation_data = validation_dataset\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17928a340>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualizing losses and accuracy\n",
    "# print(history.history)\n",
    "train_loss = history.history['loss']\n",
    "val_loss   = history.history['val_loss']\n",
    "train_acc  = history.history['accuracy']\n",
    "val_acc    = history.history['val_accuracy']\n",
    "xc         = range(269)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(xc, train_loss,label = 'Train Loss')\n",
    "plt.plot(xc, val_loss,label = 'Val Loss')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8278 - accuracy: 0.5000\n",
      "50.0\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(test_dataset)\n",
    "print(acc *100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predictImage(filename):\n",
    "    img1 = image.load_img(filename,target_size=(32,32),color_mode = \"grayscale\")\n",
    "    print(img1)\n",
    "    plt.imshow(img1,cmap='gray')\n",
    " \n",
    "    Y = image.img_to_array(img1)\n",
    "    \n",
    "    X = np.expand_dims(Y,axis=0)\n",
    "    val = model.predict(X)\n",
    "    print(val)\n",
    "    if val == 1:\n",
    "        \n",
    "        plt.xlabel(\"Real\",fontsize=30)\n",
    "        \n",
    "    \n",
    "    elif val == 0:\n",
    "        \n",
    "        plt.xlabel(\"Fake\",fontsize=30)\n",
    "\n",
    "predictImage(r\"/Users/nayansavaliya/Masters Mechatronics/2022 Summer/RAML - Project/data/bicubic/test/imagewoof_test/985.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictImage(r\"/Users/nayansavaliya/Masters Mechatronics/2022 Summer/RAML - Project/data/bicubic/test/SNGAN_bicubic_test/952.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[210.        74.85386   84.014046 ...  51.940174  84.014206  74.853966]\n",
      " [126.311264  50.78618   48.85548  ... 112.37211  227.17798   55.062515]\n",
      " [181.85095  139.74811   80.216484 ... 185.6893    47.41952   86.42856 ]\n",
      " ...\n",
      " [117.22816   60.508064 146.22131  ...  93.78925  308.35425  114.073845]\n",
      " [181.85065   86.4286    47.419773 ... 120.15541   80.21627  139.74818 ]\n",
      " [126.31114   55.06267  227.17792  ...  96.001     48.85535   50.78591 ]], shape=(32, 32), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17f11f310>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class PowerSpectrum(object):\n",
    "    def __init__(self,image_size=None,scale=1):\n",
    "        self.image_size = image_size\n",
    "        self.scale = scale\n",
    "        if self.image_size is not None:\n",
    "            self.az_mask=self.build_azimuthal_mask()\n",
    "        \n",
    "    def power2D(self,x):\n",
    "        x = tf.signal.fft2d(tf.cast(x,dtype=tf.complex64))\n",
    "        x = tf.signal.fftshift(x, axes=None, name=None)\n",
    "        return abs(x)\n",
    "     \n",
    "    def build_azimuthal_mask(self):\n",
    "        \n",
    "        x,y = np.meshgrid(np.arange(self.image_size),np.arange(self.image_size))\n",
    "        R = np.sqrt((x-self.image_size/2)**2+(y-self.image_size/2)**2)\n",
    "        masks = np.array(list(map(lambda r : (R >= r-.5) & (R < r+.5),np.arange(1,int(self.image_size/2+1),1))))\n",
    "        norm = np.sum(masks,axis=(1,2),keepdims=True)\n",
    "        masks=masks/norm\n",
    "        n=len(masks)\n",
    "        return tf.reshape(tf.cast(masks,dtype=tf.float32),(1,n,self.image_size,self.image_size))\n",
    "        \n",
    "    def az_average(self,x):\n",
    "        x=tf.reshape(x,(-1,1,self.image_size,self.image_size))\n",
    "        return tf.reduce_sum(tf.reduce_sum(tf.multiply(self.az_mask,x),axis=3),axis=2)\n",
    "    \n",
    "    def power1D(self,x):\n",
    "        x = self.power2D(x)\n",
    "        az_avg = self.az_average(x)\n",
    "        ell=np.arange(int(az_avg.shape[1]))*9\n",
    "        return tf.multiply(az_avg,tf.reshape(tf.cast(ell*(ell+1)/2/np.pi,dtype=tf.float32),(1,-1)))\n",
    "\n",
    "ss = PowerSpectrum(image_size=32).power2D(image.load_img(r\"/Users/nayansavaliya/Masters Mechatronics/2022 Summer/RAML - Project/data/bicubic/test/imagewoof_test/856.jpg\",target_size=(32,32),color_mode = \"grayscale\"))\n",
    "print(ss)\n",
    "plt.imshow(ss,cmap='gray')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[     0.    84156.35 224446.02 270031.8  260740.72 475722.56 598830.75\n",
      "  639740.1  697710.06 810709.2  664137.25 769665.94 836384.75 716103.44\n",
      "  729603.06 758634.1 ]], shape=(1, 16), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17b857460>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ss1 = PowerSpectrum(image_size=32).power1D(image.load_img(r\"/Users/nayansavaliya/Masters Mechatronics/2022 Summer/RAML - Project/data/bicubic/test/SNGAN_bicubic_test/840.jpg\",target_size=(32,32),color_mode = \"grayscale\"))\n",
    "\n",
    "print(ss1)\n",
    "plt.imshow(ss1,cmap='gray')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d6559be91acbc93f4d619e1b72121704cbae2e517629d34a1f89aedc7528f034"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
